---
title: '06. The Catches - Collusion, False Tips, and Chilling Effects' 
weight: 6 
draft: false
---

Fine-Insured Bounties (FIBs) promise a powerful way to deter dangerous
activities—from littering to reckless AI development. But no mechanism is
foolproof. Let's examine three critical challenges that must be addressed:
collusion, false accusations, and innovation chilling.

### 1. Bounty Hunter Collusion

Here's the problem: the bounty hunter who discovers wrongdoing might prefer
negotiating quietly with offenders rather than reporting them. Imagine a bounty
hunter finds a lab secretly training a dangerous AI model, which would incur a
$50 million fine, of which the bounty hunter might officially claim $10 million.
But what if the lab offers the bounty hunter $15 million to stay silent?

This type of collusion—a form of bounty hunter blackmail—is a serious threat
because it undermines the whole system. Instead of deterring crimes, it creates
a secretive black-market negotiation.

**Possible solutions include:**

- Making collusion itself a heavily punished offense.
- Paying bounties closer to the full fine amount, reducing incentives to
  negotiate privately.
- Encouraging multiple simultaneous bounty hunters, making collusion riskier.

### 2. False or Frivolous Tips

Another risk is the potential for false or frivolous bounty claims.
Opportunistic actors might submit dubious accusations, clogging courts or
investigative resources, and harassing innocent organizations.

But there's built-in protection: bounty hunters only receive payment if the
accusation results in a proven conviction. This strongly discourages completely
baseless claims.

To further reduce frivolous claims:

- Authorities could penalize demonstrably false or malicious accusations.
- Authorities could charge modest filing fees refundable upon successful
  conviction, deterring trivial or repeated nuisance claims.

While false tips are possible, careful policy design can keep them manageable.

### 3. Over-Chilling Innovation

Perhaps the biggest concern is that FIB systems could inadvertently "over-chill"
innovation. If fines are massive and violations poorly defined, researchers
might avoid any advanced or boundary-pushing work out of fear of accidentally
breaking the rules.

This chilling effect is especially problematic for beneficial research,
including work directly aimed at improving AI safety itself.

To address this:

- Clearly define illegal behaviors with well-crafted, narrowly-tailored rules.
- Use graduated penalties for ambiguous violations, reserving massive fines for
  clearly dangerous, well-defined offenses.
- Allow good-faith defenses or leniency provisions for first-time, minor
  infractions.

The goal is balance: deterring reckless danger without paralyzing legitimate,
responsible research.

### Conclusion: Careful Design Needed

None of these challenges are insurmountable. Each requires thoughtful legal,
economic, and practical design considerations. Collusion can be discouraged,
false accusations minimized, and innovation protected—all through careful policy
crafting.

The fine-insured bounty concept is powerful precisely because it's flexible.
With the right safeguards, it remains a compelling mechanism to deter
high-stakes wrongdoing, especially in fields as critical as artificial
intelligence.

We're almost done! Have we convinced you? If so, proceed to
[Next Steps - Pilots, Law Drafts, and Public Buy-In](/main-sequence/07-next-steps/).
